{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarcasm Detector using Embeddings.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "9YIgWRddCLoj"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP8rYp7M/AMg5YLHz6uew+f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tqnhu2407/sarcasm_detector_using_embeddings/blob/main/Sarcasm_Detector_using_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7s7QOyaCtzj"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from bs4 import BeautifulSoup\n",
        "import string\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW4DSu5cBctP"
      },
      "source": [
        "# Reading JSON input file and Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDGwMv2xFzMJ"
      },
      "source": [
        "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVoaInDcLzuu"
      },
      "source": [
        "26709-long data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4gUGLJLmXqO"
      },
      "source": [
        "def split_train_test(stopwords, training_size, vocab_size, max_len):\n",
        "\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    urls = []\n",
        "\n",
        "\n",
        "    with open('Sarcasm_Headlines_Dataset.json', 'r') as f:\n",
        "        for line in f:\n",
        "            obj = json.loads(line)\n",
        "            sentence = obj['headline'].lower()\n",
        "            sentence = sentence.replace(\",\", \" , \")\n",
        "            sentence = sentence.replace(\".\", \" . \")\n",
        "            sentence = sentence.replace(\"-\", \" - \")\n",
        "            sentence = sentence.replace(\"/\", \" / \")\n",
        "            soup = BeautifulSoup(sentence)\n",
        "            sentence = soup.get_text() # remove HTML tags\n",
        "            words = sentence.split()\n",
        "            filtered_sentence = \"\"\n",
        "            for word in words:\n",
        "                word = word.translate(table) # remove punctuation\n",
        "                if word not in stopwords: # remove stop words\n",
        "                    filtered_sentence = filtered_sentence + word + \" \"\n",
        "            sentences.append(filtered_sentence)\n",
        "            urls.append(obj['article_link'])\n",
        "            labels.append(obj['is_sarcastic'])\n",
        "\n",
        "    training_sentences = sentences[0:training_size]\n",
        "    testing_sentences = sentences[training_size:]\n",
        "    training_labels = labels[0:training_size]\n",
        "    testing_labels = labels[training_size:]\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "    training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "    training_padded = pad_sequences(training_sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "    tokenizer.fit_on_texts(testing_sentences)\n",
        "    testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "    testing_padded = pad_sequences(testing_sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "    training_padded = np.array(training_padded)\n",
        "    training_labels = np.array(training_labels)\n",
        "    testing_padded = np.array(testing_padded)\n",
        "    testing_labels = np.array(testing_labels)\n",
        "\n",
        "    return training_padded, testing_padded, training_labels, testing_labels, tokenizer, sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hCtwuFHp6-l"
      },
      "source": [
        "training_size = 23000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UexqBMMqsIhE"
      },
      "source": [
        "vocab_size = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8ZR-bbyBTvg"
      },
      "source": [
        "training_padded, testing_padded, training_labels, testing_labels, tokenizer, sentences = split_train_test(stopwords, training_size, vocab_size, 85)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwjcLEE9BEmh"
      },
      "source": [
        "# Embeddings in Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkniMoAXBH3I"
      },
      "source": [
        "## Building a Sarcasm Detector Using Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2abTtvYByS7"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(10000, 16), # vocab_size, embedding_dim\n",
        "                             tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                             tf.keras.layers.Dense(24, activation='relu'),\n",
        "                             tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QtOmYfrB0Ds"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNaWQfySB12W"
      },
      "source": [
        "* The embedding has a 10,000-word vocab, each word is a vector in 16D => The total number of trainable parameters = 160,000.\n",
        "* The average pooling layer has 0 trainable params (it's just averaging the params in the embedding layer before it to get a single 16-value vector).\n",
        "* 24-neuron dense layer effectively calculates using weights and biases, so it will need to learn 24 x 16 + 24 = 408 params.\n",
        "* Final single-neuron network (I already learned Sigmoid function/Logistic regression), there will be 24 + 1 = 25 params to learn.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rpZd7rPB1kE"
      },
      "source": [
        "history = model.fit(training_padded, training_labels, validation_split=0.33, epochs=35)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tZTzknuB5yI"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXoBRy7R1QFk"
      },
      "source": [
        "def plot_accuracy(history):\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('acccuracy')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaJZNYeZ1ZpR"
      },
      "source": [
        "def plot_loss(history):\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z42nr1tB-HN"
      },
      "source": [
        "The validation data likely contains many words that aren't present in the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrHUE_1zCBcI"
      },
      "source": [
        "**Overfitting**: while the validation accuracy is dropping a little over time, its loss is increasing sharply."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad6oS2qFCI9L"
      },
      "source": [
        "## Reducing Overfitting in Language Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YIgWRddCLoj"
      },
      "source": [
        "### Adjusting the learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XI2mwuwCNlX"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(10000, 16), # vocab_size, embedding_dim\n",
        "                             tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                             tf.keras.layers.Dense(24, activation='relu'),\n",
        "                             tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False) # default = 0.001\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMeS_D0iCPtR"
      },
      "source": [
        "history = model.fit(training_padded, training_labels, validation_split=0.33, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UMIzxH6CRJS"
      },
      "source": [
        "plot_accuracy(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKRkOtIdCScC"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDoKRXNEJXQ2"
      },
      "source": [
        "### Exploring vocab size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlWNAZaqJa3w"
      },
      "source": [
        "wc = tokenizer.word_counts\n",
        "print(wc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VuWv345Jfbh"
      },
      "source": [
        "from collections import OrderedDict\n",
        "newlist = (OrderedDict(sorted(wc.items(), key=lambda t: t[1], reverse=True)))\n",
        "print(newlist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VKhI7f2KL8o"
      },
      "source": [
        "Plot our vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8O0jYz7J6ld"
      },
      "source": [
        "xs=[]\n",
        "ys=[]\n",
        "curr_x = 1\n",
        "for item in newlist:\n",
        " xs.append(curr_x)\n",
        " curr_x=curr_x+1\n",
        " ys.append(newlist[item])\n",
        "plt.plot(xs,ys)\n",
        "plt.xlabel('word_index')\n",
        "plt.ylabel('frequency')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzOEmTecKqfe"
      },
      "source": [
        "Very few words are used many times.\n",
        "\n",
        "A lot of words are used very few times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn_f0TrIK6HK"
      },
      "source": [
        "Zoom the diagram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT-Tg-qjKO2p"
      },
      "source": [
        "xs=[]\n",
        "ys=[]\n",
        "curr_x = 1\n",
        "for item in newlist:\n",
        " xs.append(curr_x)\n",
        " curr_x=curr_x+1\n",
        " ys.append(newlist[item])\n",
        "plt.plot(xs,ys)\n",
        "plt.xlabel('word_index')\n",
        "plt.ylabel('frequency')\n",
        "plt.axis([300,10000,0,100])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNoJDfne3dBQ"
      },
      "source": [
        "Reduce the vocab_size to 2,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0nO85aV7WdO"
      },
      "source": [
        "vocab_size = 2000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP6ay7bG6n8_"
      },
      "source": [
        "training_padded, testing_padded, training_labels, testing_labels, tokenizer = split_train_test(stopwords, training_size, vocab_size, 85)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDkzzBk6u55S"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(vocab_size, 16), # vocab_size, embedding_dim\n",
        "                             tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                             tf.keras.layers.Dense(24, activation='relu'),\n",
        "                             tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False) # default = 0.001\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zbpPiRau_nb"
      },
      "source": [
        "history = model.fit(training_padded, training_labels, validation_split=0.33, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhHlUi1JvA2P"
      },
      "source": [
        "plot_accuracy(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LED13KE_vpFS"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUv50BM2xurY"
      },
      "source": [
        "### Exploring embedding dimensions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtCMn-1_yRpw"
      },
      "source": [
        "\"Best practice for embedding size is to have it be the fourth root of the vocab size.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfSd187ZxdhK"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(vocab_size, 7), # vocab_size, embedding_dim\n",
        "                             tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                             tf.keras.layers.Dense(24, activation='relu'),\n",
        "                             tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False) # default = 0.001\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbJbHfdHzBkr"
      },
      "source": [
        "history = model.fit(training_padded, training_labels, validation_split=0.33, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ph-doUzzFBU"
      },
      "source": [
        "plot_accuracy(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1wK5moK2gGw"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbER_71C2-0w"
      },
      "source": [
        "### Exploring the model architecture\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1P009q8CcTP"
      },
      "source": [
        "Reduce to 8 neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIGBXVNm2h-x"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(vocab_size, 7), # vocab_size, embedding_dim\n",
        "                             tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                             tf.keras.layers.Dense(8, activation='relu'),\n",
        "                             tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False) # default = 0.001\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcgFCcKaCiVT"
      },
      "source": [
        "history = model.fit(training_padded, training_labels, validation_split=0.33, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0N268QsCi2t"
      },
      "source": [
        "plot_accuracy(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTrrmiO3Cmv8"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnyHYEfhHJtA"
      },
      "source": [
        "### Using dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoyKK4bTHIxN"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(vocab_size, 7), # vocab_size, embedding_dim\n",
        "                             tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                             tf.keras.layers.Dense(8, activation='relu'),\n",
        "                             tf.keras.layers.Dropout(0.25),\n",
        "                             tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False) # default = 0.001\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbt3TowFKUBf"
      },
      "source": [
        "history = model.fit(training_padded, training_labels, validation_split=0.33, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSeWHg4XLbfO"
      },
      "source": [
        "plot_accuracy(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaNstEEMLgpY"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqJ6-yAGJ3Wf"
      },
      "source": [
        "### Using regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwdBM4zrBW_x"
      },
      "source": [
        "* L1\n",
        "* L2 (commonly used in NLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unumqHft_UGH"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                        tf.keras.layers.Embedding(vocab_size, 7),\n",
        "                        tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                        tf.keras.layers.Dense(8, activation='relu', kernel_regularizer = tf.keras.regularizers.l2(0.01)),\n",
        "                        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False) # default = 0.001\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewEHmLij_o86"
      },
      "source": [
        "history = model.fit(training_padded, training_labels, validation_split=0.33, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5cQtzlM_paI"
      },
      "source": [
        "plot_accuracy(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5TzuSV6_s12"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgwAJvb2IcH6"
      },
      "source": [
        "### Other optimization consideration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GowABxuzBram"
      },
      "source": [
        "#### Exploring sentence length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joIQ_wB6B_QR"
      },
      "source": [
        "xs=[]\n",
        "ys=[]\n",
        "current_item=1\n",
        "for item in sentences:\n",
        "    xs.append(current_item)\n",
        "    current_item=current_item+1\n",
        "    ys.append(len(item))\n",
        "newys = sorted(ys)\n",
        "\n",
        "plt.plot(xs,newys)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvduVbDxCowY"
      },
      "source": [
        "There are more than 25,000 sentences that have a length of < 100 words. So we reduce the max_length to 85."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFSg8u6uCICS"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                        tf.keras.layers.Embedding(vocab_size, 7),\n",
        "                        tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                        tf.keras.layers.Dense(8, activation='relu', kernel_regularizer = tf.keras.regularizers.l2(0.01)),\n",
        "                        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False) # default = 0.001\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSqVR61EDv8T"
      },
      "source": [
        "history = model.fit(training_padded, training_labels, validation_split=0.33, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAozW5JBDyzq"
      },
      "source": [
        "plot_accuracy(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCzGgM8DDzpu"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}